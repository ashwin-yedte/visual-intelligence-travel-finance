{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWiYmHdpghqtrKkC7eoXsF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwin-yedte/visual-intelligence-travel-finance/blob/main/notebooks/Step_2_Theme_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================================================================\n",
        "STEP 2: THEME EXTRACTION AND AGGREGATION\n",
        "================================================================================\n",
        "Project: Visual Intelligence for Travel and Finance Optimization\n",
        "\n",
        "Course: AIMLCZG628T\n",
        "\n",
        "Author: Ashwin Kumar Y (2023AC05628)\n",
        "\n",
        "Institution: BITS Pilani\n",
        "\n",
        "Version: 1.0.0\n",
        "\n",
        "Date: January 2026\n",
        "\n",
        "\n",
        "Dependencies: Requires Step 1 output (step1_analysis_results.json)\n",
        "================================================================================"
      ],
      "metadata": {
        "id": "k5rJz145ytMO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxK4rwdpyci5",
        "outputId": "da016691-a690-433e-9f41-2e879d021596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 2: THEME EXTRACTION AND AGGREGATION\n",
            "================================================================================\n",
            "\n",
            "Project: Visual Intelligence for Travel and Finance Optimization\n",
            "Author: Ashwin Kumar Y (2023AC05628)\n",
            "Version: 1.0.0\n",
            "\n",
            "================================================================================\n",
            "SETUP: Installing required packages\n",
            "================================================================================\n",
            "Installing numpy...\n",
            "Installing matplotlib...\n",
            "\n",
            "================================================================================\n",
            "SETUP COMPLETE: All packages installed\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 2: THEME EXTRACTION AND AGGREGATION\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nProject: Visual Intelligence for Travel and Finance Optimization\")\n",
        "print(\"Author: Ashwin Kumar Y (2023AC05628)\")\n",
        "print(\"Version: 1.0.0\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SETUP: Installing required packages\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Install dependencies (minimal for Step 2)\n",
        "import sys\n",
        "print(\"Installing numpy...\")\n",
        "!pip install -q numpy\n",
        "\n",
        "print(\"Installing matplotlib...\")\n",
        "!pip install -q matplotlib\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SETUP COMPLETE: All packages installed\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import **Libraries**"
      ],
      "metadata": {
        "id": "Rs9sHbvzy4t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"=\"*80)\n",
        "print(\"IMPORTS: Loading required libraries\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Core Python libraries\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, List, Tuple, Any\n",
        "from collections import Counter, defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "# Numerical computing\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Google Colab specific\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\nLibrary versions:\")\n",
        "print(f\"  NumPy: {np.__version__}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPORTS COMPLETE: All libraries loaded successfully\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbf7Tv40y6Pe",
        "outputId": "0b194bbc-9ef0-4251-877d-a075de3ad391"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "IMPORTS: Loading required libraries\n",
            "================================================================================\n",
            "\n",
            "Library versions:\n",
            "  NumPy: 2.0.2\n",
            "\n",
            "================================================================================\n",
            "IMPORTS COMPLETE: All libraries loaded successfully\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration**"
      ],
      "metadata": {
        "id": "8TF5D9jGzBq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CONFIGURATION: Setting up system parameters\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Configuration for Step 2: Theme Extraction\n",
        "    \"\"\"\n",
        "\n",
        "    # Input/Output files\n",
        "    INPUT_JSON_FILE = \"step1_analysis_results.json\"\n",
        "    OUTPUT_JSON_FILE = \"step2_theme_extraction_results.json\"\n",
        "    OUTPUT_SUMMARY_FILE = \"step2_theme_summary.txt\"\n",
        "    OUTPUT_VISUALIZATION_FILE = \"step2_theme_visualization.png\"\n",
        "\n",
        "    # Theme extraction thresholds\n",
        "    HIGH_CONSISTENCY_THRESHOLD = 0.70  # 70% of images\n",
        "    MEDIUM_CONSISTENCY_THRESHOLD = 0.40  # 40% of images\n",
        "    LOW_CONSISTENCY_THRESHOLD = 0.20  # 20% of images\n",
        "\n",
        "    # Score thresholds\n",
        "    HIGH_SCORE_THRESHOLD = 0.75\n",
        "    MEDIUM_SCORE_THRESHOLD = 0.60\n",
        "    LOW_SCORE_THRESHOLD = 0.45\n",
        "\n",
        "    # Outlier detection\n",
        "    OUTLIER_STD_MULTIPLIER = 2.0  # Number of std deviations for outlier\n",
        "    MIN_IMAGES_FOR_OUTLIER_DETECTION = 3\n",
        "\n",
        "    # Theme selection\n",
        "    MAX_PRIMARY_THEMES = 2\n",
        "    MAX_SECONDARY_THEMES = 3\n",
        "\n",
        "    # Visualization\n",
        "    VISUALIZATION_DPI = 150\n",
        "\n",
        "    # Metadata\n",
        "    VERSION = \"1.0.0\"\n",
        "    STEP_NAME = \"Step 2: Theme Extraction and Aggregation\"\n",
        "    AUTHOR = \"Ashwin Kumar Y (2023AC05628)\"\n",
        "    PROJECT = \"Visual Intelligence for Travel and Finance Optimization\"\n",
        "\n",
        "    @classmethod\n",
        "    def display_config(cls):\n",
        "        \"\"\"Display current configuration\"\"\"\n",
        "        print(\"\\nCurrent Configuration:\")\n",
        "        print(f\"  Input file: {cls.INPUT_JSON_FILE}\")\n",
        "        print(f\"  High consistency threshold: {cls.HIGH_CONSISTENCY_THRESHOLD*100}%\")\n",
        "        print(f\"  Medium consistency threshold: {cls.MEDIUM_CONSISTENCY_THRESHOLD*100}%\")\n",
        "        print(f\"  Max primary themes: {cls.MAX_PRIMARY_THEMES}\")\n",
        "        print(f\"  Max secondary themes: {cls.MAX_SECONDARY_THEMES}\")\n",
        "\n",
        "# Display configuration\n",
        "Config.display_config()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONFIGURATION COMPLETE: System parameters set\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSr8UvChzCwO",
        "outputId": "34b00f92-3fc1-47c9-93e4-f3c8e75cf64d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CONFIGURATION: Setting up system parameters\n",
            "================================================================================\n",
            "\n",
            "Current Configuration:\n",
            "  Input file: step1_analysis_results.json\n",
            "  High consistency threshold: 70.0%\n",
            "  Medium consistency threshold: 40.0%\n",
            "  Max primary themes: 2\n",
            "  Max secondary themes: 3\n",
            "\n",
            "================================================================================\n",
            "CONFIGURATION COMPLETE: System parameters set\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ================================================================================\n",
        " LOAD STEP 1 ANALYSIS RESULTS\n",
        "================================================================================\n",
        "Purpose: Load and validate the JSON output from Step 1.\n",
        "=============================================================================="
      ],
      "metadata": {
        "id": "yt2VDwPUzcxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"DATA LOADING: Importing Step 1 analysis results\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check if file exists in current directory\n",
        "if not os.path.exists(Config.INPUT_JSON_FILE):\n",
        "    print(f\"\\nERROR: Input file '{Config.INPUT_JSON_FILE}' not found\")\n",
        "    print(\"\\nPlease upload the file from Step 1:\")\n",
        "    print(\"  1. You should have downloaded 'step1_analysis_results.json' from Step 1\")\n",
        "    print(\"  2. Click the 'Choose Files' button below to upload it\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    # Trigger file upload\n",
        "    print(\"Waiting for file upload...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if Config.INPUT_JSON_FILE in uploaded:\n",
        "        print(f\"\\nFile '{Config.INPUT_JSON_FILE}' uploaded successfully!\")\n",
        "\n",
        "        # Save the uploaded file\n",
        "        with open(Config.INPUT_JSON_FILE, 'wb') as f:\n",
        "            f.write(uploaded[Config.INPUT_JSON_FILE])\n",
        "    else:\n",
        "        print(f\"\\nERROR: Expected file '{Config.INPUT_JSON_FILE}' but got:\")\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"  - {filename}\")\n",
        "        print(\"\\nPlease rename your file to 'step1_analysis_results.json' and try again.\")\n",
        "        step1_data = None\n",
        "\n",
        "# Load the JSON file\n",
        "if os.path.exists(Config.INPUT_JSON_FILE):\n",
        "    print(f\"\\nLoading data from: {Config.INPUT_JSON_FILE}\")\n",
        "\n",
        "    try:\n",
        "        with open(Config.INPUT_JSON_FILE, 'r', encoding='utf-8') as f:\n",
        "            step1_data = json.load(f)\n",
        "\n",
        "        # Validate structure\n",
        "        print(\"\\nValidating data structure...\")\n",
        "\n",
        "        required_keys = ['success', 'num_images', 'per_image_analysis']\n",
        "        missing_keys = [key for key in required_keys if key not in step1_data]\n",
        "\n",
        "        if missing_keys:\n",
        "            print(f\"ERROR: Missing required keys: {missing_keys}\")\n",
        "            step1_data = None\n",
        "        elif not step1_data.get('success', False):\n",
        "            print(f\"ERROR: Step 1 analysis was not successful\")\n",
        "            print(f\"Reason: {step1_data.get('error', 'Unknown error')}\")\n",
        "            step1_data = None\n",
        "        else:\n",
        "            # Display summary\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"DATA LOADED SUCCESSFULLY\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            print(f\"\\nFile information:\")\n",
        "            file_size = os.path.getsize(Config.INPUT_JSON_FILE)\n",
        "            print(f\"  File size: {file_size/1024:.2f} KB\")\n",
        "            print(f\"  Total images: {step1_data['num_images']}\")\n",
        "\n",
        "            # Count successful analyses\n",
        "            successful_count = sum(\n",
        "                1 for analysis in step1_data['per_image_analysis'].values()\n",
        "                if analysis.get('success', False)\n",
        "            )\n",
        "            failed_count = step1_data['num_images'] - successful_count\n",
        "\n",
        "            print(f\"  Successful analyses: {successful_count}\")\n",
        "            print(f\"  Failed analyses: {failed_count}\")\n",
        "\n",
        "            # Check for batch statistics\n",
        "            has_batch_stats = 'batch_statistics' in step1_data and bool(step1_data['batch_statistics'])\n",
        "            print(f\"  Batch statistics available: {'Yes' if has_batch_stats else 'No'}\")\n",
        "\n",
        "            # Display image list\n",
        "            print(f\"\\nImages in dataset:\")\n",
        "            for img_id, analysis in step1_data['per_image_analysis'].items():\n",
        "                status = \"SUCCESS\" if analysis.get('success', False) else \"FAILED\"\n",
        "                confidence = analysis.get('confidence', 'N/A').upper() if analysis.get('success') else 'N/A'\n",
        "                print(f\"  - {img_id}: {status} (Confidence: {confidence})\")\n",
        "\n",
        "            # Display metadata if available\n",
        "            if 'metadata' in step1_data:\n",
        "                print(f\"\\nStep 1 metadata:\")\n",
        "                metadata = step1_data['metadata']\n",
        "                print(f\"  Generated: {metadata.get('generated_at', 'Unknown')}\")\n",
        "                print(f\"  Version: {metadata.get('version', 'Unknown')}\")\n",
        "                if 'configuration' in metadata:\n",
        "                    config = metadata['configuration']\n",
        "                    print(f\"  CLIP model: {config.get('clip_model', 'Unknown')}\")\n",
        "                    print(f\"  Device used: {config.get('device_used', 'Unknown')}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Data ready for theme extraction\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"\\nERROR: Invalid JSON file\")\n",
        "        print(f\"Details: {str(e)}\")\n",
        "        step1_data = None\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: Failed to load file\")\n",
        "        print(f\"Details: {str(e)}\")\n",
        "        step1_data = None\n",
        "else:\n",
        "    step1_data = None\n",
        "\n",
        "# Set flag for next cells\n",
        "if step1_data is not None:\n",
        "    data_loaded = True\n",
        "    print(\"\\nProceed to next cell for theme extraction.\")\n",
        "else:\n",
        "    data_loaded = False\n",
        "    print(\"\\nPlease fix the errors above before proceeding.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqw6idlrze1u",
        "outputId": "487d7db5-aa0d-47ad-b591-4fa78d942f75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA LOADING: Importing Step 1 analysis results\n",
            "================================================================================\n",
            "\n",
            "Loading data from: step1_analysis_results.json\n",
            "\n",
            "Validating data structure...\n",
            "\n",
            "================================================================================\n",
            "DATA LOADED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "File information:\n",
            "  File size: 29.99 KB\n",
            "  Total images: 5\n",
            "  Successful analyses: 5\n",
            "  Failed analyses: 0\n",
            "  Batch statistics available: Yes\n",
            "\n",
            "Images in dataset:\n",
            "  - Beach1: SUCCESS (Confidence: LOW)\n",
            "  - Beach2: SUCCESS (Confidence: LOW)\n",
            "  - Beach3: SUCCESS (Confidence: LOW)\n",
            "  - Beach4: SUCCESS (Confidence: LOW)\n",
            "  - Beach5: SUCCESS (Confidence: LOW)\n",
            "\n",
            "Step 1 metadata:\n",
            "  Generated: 2026-01-03T16:08:18.620134\n",
            "  Version: 1.0.0\n",
            "  CLIP model: openai/clip-vit-base-patch32\n",
            "  Device used: cpu\n",
            "\n",
            "================================================================================\n",
            "Data ready for theme extraction\n",
            "================================================================================\n",
            "\n",
            "Proceed to next cell for theme extraction.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================================================================\n",
        "THEME EXTRACTOR CLASS\n",
        "================================================================================\n",
        "Purpose: Core class for extracting and aggregating themes from Step 1 results.\n",
        "         Handles consistency analysis, outlier detection, and theme ranking.\n",
        "         \n",
        "================================================================================"
      ],
      "metadata": {
        "id": "6spQBMREz_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"THEME EXTRACTOR: Initializing theme extraction engine\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class ThemeExtractor:\n",
        "    \"\"\"\n",
        "    Extract and aggregate themes from multiple image analyses.\n",
        "\n",
        "    This class takes the output from Step 1 and performs sophisticated\n",
        "    theme extraction by:\n",
        "    - Analyzing theme consistency across images\n",
        "    - Detecting and handling outliers\n",
        "    - Ranking themes by reliability\n",
        "    - Classifying themes into primary and secondary\n",
        "    - Computing confidence metrics\n",
        "\n",
        "    The goal is to identify the user's true preferences by finding themes\n",
        "    that consistently appear across multiple images, rather than themes\n",
        "    that only appear in one image (which might be outliers).\n",
        "\n",
        "    Attributes:\n",
        "        step1_data (Dict): Complete output from Step 1\n",
        "        num_images (int): Number of images analyzed\n",
        "        successful_analyses (List): List of successful image analyses\n",
        "\n",
        "    Example:\n",
        "        >>> extractor = ThemeExtractor(step1_data)\n",
        "        >>> themes = extractor.extract_themes()\n",
        "        >>> print(themes['primary_themes'])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, step1_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize theme extractor with Step 1 results.\n",
        "\n",
        "        Args:\n",
        "            step1_data: Dictionary containing Step 1 analysis results\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If step1_data is invalid or empty\n",
        "        \"\"\"\n",
        "        if not step1_data or not step1_data.get('success', False):\n",
        "            raise ValueError(\"Invalid or unsuccessful Step 1 data provided\")\n",
        "\n",
        "        self.step1_data = step1_data\n",
        "        self.num_images = step1_data['num_images']\n",
        "\n",
        "        # Extract successful analyses only\n",
        "        self.successful_analyses = [\n",
        "            analysis for analysis in step1_data['per_image_analysis'].values()\n",
        "            if analysis.get('success', False)\n",
        "        ]\n",
        "\n",
        "        if not self.successful_analyses:\n",
        "            raise ValueError(\"No successful analyses found in Step 1 data\")\n",
        "\n",
        "        print(f\"\\nTheme extractor initialized:\")\n",
        "        print(f\"  Total images: {self.num_images}\")\n",
        "        print(f\"  Successful analyses: {len(self.successful_analyses)}\")\n",
        "\n",
        "    def extract_themes(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Main method to extract themes from Step 1 results.\n",
        "\n",
        "        This orchestrates the complete theme extraction pipeline:\n",
        "        1. Collect all scene scores across images\n",
        "        2. Compute theme statistics (mean, std, consistency)\n",
        "        3. Detect outliers\n",
        "        4. Rank themes by reliability\n",
        "        5. Select primary and secondary themes\n",
        "        6. Compute overall confidence\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing:\n",
        "            {\n",
        "                'primary_themes': List[Dict],      # Top 1-2 dominant themes\n",
        "                'secondary_themes': List[Dict],    # Next 3-5 supporting themes\n",
        "                'all_theme_statistics': Dict,      # Complete stats for all themes\n",
        "                'outliers_detected': List[Dict],   # Images/themes flagged as outliers\n",
        "                'consistency_level': str,          # 'high', 'medium', 'low'\n",
        "                'confidence': str,                 # Overall confidence level\n",
        "                'summary': Dict                    # Human-readable summary\n",
        "            }\n",
        "\n",
        "        Example:\n",
        "            >>> themes = extractor.extract_themes()\n",
        "            >>> for theme in themes['primary_themes']:\n",
        "            >>>     print(f\"{theme['prompt']}: {theme['consistency']*100}%\")\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"THEME EXTRACTION PIPELINE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Step 1: Collect scene scores\n",
        "        print(\"\\nStep 1: Collecting scene scores across all images...\")\n",
        "        all_scene_scores = self._collect_scene_scores()\n",
        "        print(f\"  Collected scores for {len(all_scene_scores)} unique themes\")\n",
        "\n",
        "        # Step 2: Compute statistics\n",
        "        print(\"\\nStep 2: Computing theme statistics...\")\n",
        "        theme_statistics = self._compute_theme_statistics(all_scene_scores)\n",
        "        print(f\"  Computed statistics for {len(theme_statistics)} themes\")\n",
        "\n",
        "        # Step 3: Detect outliers\n",
        "        print(\"\\nStep 3: Detecting outliers...\")\n",
        "        outliers = self._detect_outliers(theme_statistics)\n",
        "        if outliers:\n",
        "            print(f\"  Found {len(outliers)} potential outlier(s)\")\n",
        "        else:\n",
        "            print(f\"  No outliers detected\")\n",
        "\n",
        "        # Step 4: Rank themes\n",
        "        print(\"\\nStep 4: Ranking themes by consistency and score...\")\n",
        "        ranked_themes = self._rank_themes(theme_statistics)\n",
        "        print(f\"  Themes ranked by reliability\")\n",
        "\n",
        "        # Step 5: Select primary and secondary themes\n",
        "        print(\"\\nStep 5: Selecting primary and secondary themes...\")\n",
        "        primary_themes = self._select_primary_themes(ranked_themes)\n",
        "        secondary_themes = self._select_secondary_themes(ranked_themes, primary_themes)\n",
        "        print(f\"  Primary themes: {len(primary_themes)}\")\n",
        "        print(f\"  Secondary themes: {len(secondary_themes)}\")\n",
        "\n",
        "        # Step 6: Compute consistency level\n",
        "        print(\"\\nStep 6: Computing overall consistency level...\")\n",
        "        consistency_level = self._compute_consistency_level(primary_themes)\n",
        "        print(f\"  Consistency level: {consistency_level.upper()}\")\n",
        "\n",
        "        # Step 7: Compute confidence\n",
        "        print(\"\\nStep 7: Computing overall confidence...\")\n",
        "        confidence = self._compute_overall_confidence(primary_themes, consistency_level)\n",
        "        print(f\"  Confidence: {confidence.upper()}\")\n",
        "\n",
        "        # Step 8: Generate summary\n",
        "        print(\"\\nStep 8: Generating summary...\")\n",
        "        summary = self._generate_summary(primary_themes, secondary_themes, consistency_level, confidence)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"THEME EXTRACTION COMPLETE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Return complete results\n",
        "        return {\n",
        "            'primary_themes': primary_themes,\n",
        "            'secondary_themes': secondary_themes,\n",
        "            'all_theme_statistics': theme_statistics,\n",
        "            'outliers_detected': outliers,\n",
        "            'consistency_level': consistency_level,\n",
        "            'confidence': confidence,\n",
        "            'summary': summary,\n",
        "            'num_images_analyzed': len(self.successful_analyses)\n",
        "        }\n",
        "\n",
        "    def _collect_scene_scores(self) -> Dict[str, List[float]]:\n",
        "        \"\"\"\n",
        "        Collect all scene scores from successful analyses.\n",
        "\n",
        "        Creates a mapping from each theme/prompt to its scores across\n",
        "        all images. This allows us to see how consistently each theme\n",
        "        appears.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping theme to list of scores\n",
        "            Example: {\n",
        "                \"tropical beach\": [0.85, 0.82, 0.88],\n",
        "                \"rocky coastline\": [0.32, 0.28, 0.35]\n",
        "            }\n",
        "        \"\"\"\n",
        "        all_scores = defaultdict(list)\n",
        "\n",
        "        for analysis in self.successful_analyses:\n",
        "            scene_scores = analysis.get('scene_scores', {})\n",
        "            for prompt, score in scene_scores.items():\n",
        "                all_scores[prompt].append(float(score))\n",
        "\n",
        "        return dict(all_scores)\n",
        "\n",
        "    def _compute_theme_statistics(self, all_scene_scores: Dict[str, List[float]]) -> Dict[str, Dict]:\n",
        "        \"\"\"\n",
        "        Compute comprehensive statistics for each theme.\n",
        "\n",
        "        For each theme, computes:\n",
        "        - Mean score (average across images)\n",
        "        - Standard deviation (measure of variability)\n",
        "        - Min and max scores\n",
        "        - Consistency (fraction of images with high score)\n",
        "        - Appearance count (number of images with score > threshold)\n",
        "\n",
        "        Args:\n",
        "            all_scene_scores: Dictionary mapping themes to score lists\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with detailed statistics for each theme\n",
        "        \"\"\"\n",
        "        statistics = {}\n",
        "        threshold = Config.MEDIUM_SCORE_THRESHOLD\n",
        "\n",
        "        for prompt, scores in all_scene_scores.items():\n",
        "            scores_array = np.array(scores)\n",
        "\n",
        "            # Count appearances above threshold\n",
        "            appears_count = int(np.sum(scores_array > threshold))\n",
        "            consistency = appears_count / len(self.successful_analyses)\n",
        "\n",
        "            statistics[prompt] = {\n",
        "                'mean_score': float(np.mean(scores_array)),\n",
        "                'std_score': float(np.std(scores_array)),\n",
        "                'min_score': float(np.min(scores_array)),\n",
        "                'max_score': float(np.max(scores_array)),\n",
        "                'median_score': float(np.median(scores_array)),\n",
        "                'consistency': consistency,\n",
        "                'appears_in_images': appears_count,\n",
        "                'total_images': len(self.successful_analyses),\n",
        "                'scores': scores  # Keep original scores for outlier detection\n",
        "            }\n",
        "\n",
        "        return statistics\n",
        "\n",
        "    def _detect_outliers(self, theme_statistics: Dict[str, Dict]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Detect outlier themes or images.\n",
        "\n",
        "        An outlier is defined as:\n",
        "        - A theme with very high score in one image but low in others\n",
        "        - A theme with very high variability (large std deviation)\n",
        "\n",
        "        Uses statistical method: values beyond mean Â± (multiplier * std)\n",
        "\n",
        "        Args:\n",
        "            theme_statistics: Dictionary with theme statistics\n",
        "\n",
        "        Returns:\n",
        "            List of detected outliers with details\n",
        "        \"\"\"\n",
        "        outliers = []\n",
        "\n",
        "        # Only detect outliers if we have enough images\n",
        "        if len(self.successful_analyses) < Config.MIN_IMAGES_FOR_OUTLIER_DETECTION:\n",
        "            return outliers\n",
        "\n",
        "        for prompt, stats in theme_statistics.items():\n",
        "            scores = stats['scores']\n",
        "            mean = stats['mean_score']\n",
        "            std = stats['std_score']\n",
        "\n",
        "            # Skip if std is too small (consistent theme)\n",
        "            if std < 0.05:\n",
        "                continue\n",
        "\n",
        "            # Check for outlier scores\n",
        "            threshold_high = mean + (Config.OUTLIER_STD_MULTIPLIER * std)\n",
        "            threshold_low = mean - (Config.OUTLIER_STD_MULTIPLIER * std)\n",
        "\n",
        "            for idx, score in enumerate(scores):\n",
        "                if score > threshold_high or score < threshold_low:\n",
        "                    outliers.append({\n",
        "                        'prompt': prompt,\n",
        "                        'image_index': idx,\n",
        "                        'score': float(score),\n",
        "                        'mean': mean,\n",
        "                        'std': std,\n",
        "                        'deviation': abs(score - mean) / std if std > 0 else 0,\n",
        "                        'type': 'high' if score > threshold_high else 'low'\n",
        "                    })\n",
        "\n",
        "        return outliers\n",
        "\n",
        "    def _rank_themes(self, theme_statistics: Dict[str, Dict]) -> List[Tuple[str, Dict]]:\n",
        "        \"\"\"\n",
        "        Rank themes by reliability.\n",
        "\n",
        "        Ranking criteria (in order of importance):\n",
        "        1. Consistency (how often theme appears across images)\n",
        "        2. Mean score (average similarity)\n",
        "        3. Low std deviation (stable scores = more reliable)\n",
        "\n",
        "        Args:\n",
        "            theme_statistics: Dictionary with theme statistics\n",
        "\n",
        "        Returns:\n",
        "            List of (prompt, statistics) tuples sorted by reliability\n",
        "        \"\"\"\n",
        "        # Create ranking score for each theme\n",
        "        ranked = []\n",
        "\n",
        "        for prompt, stats in theme_statistics.items():\n",
        "            # Composite ranking score\n",
        "            # Consistency is most important (weight: 0.5)\n",
        "            # Mean score is secondary (weight: 0.3)\n",
        "            # Low std is bonus (weight: 0.2, inverted)\n",
        "            ranking_score = (\n",
        "                stats['consistency'] * 0.5 +\n",
        "                stats['mean_score'] * 0.3 +\n",
        "                (1.0 - min(stats['std_score'], 0.3) / 0.3) * 0.2\n",
        "            )\n",
        "\n",
        "            ranked.append((prompt, stats, ranking_score))\n",
        "\n",
        "        # Sort by ranking score (descending)\n",
        "        ranked.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Return (prompt, stats) tuples without ranking score\n",
        "        return [(prompt, stats) for prompt, stats, _ in ranked]\n",
        "\n",
        "    def _select_primary_themes(self, ranked_themes: List[Tuple[str, Dict]]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Select primary (dominant) themes.\n",
        "\n",
        "        Primary themes must have:\n",
        "        - High consistency (>= threshold)\n",
        "        - High mean score\n",
        "        - Appear in majority of images\n",
        "\n",
        "        Args:\n",
        "            ranked_themes: List of themes sorted by reliability\n",
        "\n",
        "        Returns:\n",
        "            List of primary theme dictionaries\n",
        "        \"\"\"\n",
        "        primary = []\n",
        "\n",
        "        for prompt, stats in ranked_themes:\n",
        "            # Check if qualifies as primary theme\n",
        "            if (stats['consistency'] >= Config.MEDIUM_CONSISTENCY_THRESHOLD and\n",
        "                stats['mean_score'] >= Config.MEDIUM_SCORE_THRESHOLD):\n",
        "\n",
        "                primary.append({\n",
        "                    'prompt': prompt,\n",
        "                    'consistency': stats['consistency'],\n",
        "                    'mean_score': stats['mean_score'],\n",
        "                    'std_score': stats['std_score'],\n",
        "                    'appears_in_images': stats['appears_in_images'],\n",
        "                    'total_images': stats['total_images'],\n",
        "                    'confidence_level': self._classify_theme_confidence(stats)\n",
        "                })\n",
        "\n",
        "                # Limit to max primary themes\n",
        "                if len(primary) >= Config.MAX_PRIMARY_THEMES:\n",
        "                    break\n",
        "\n",
        "        return primary\n",
        "\n",
        "    def _select_secondary_themes(self, ranked_themes: List[Tuple[str, Dict]],\n",
        "                                 primary_themes: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Select secondary (supporting) themes.\n",
        "\n",
        "        Secondary themes:\n",
        "        - Not already selected as primary\n",
        "        - Have moderate consistency or score\n",
        "        - Provide additional context\n",
        "\n",
        "        Args:\n",
        "            ranked_themes: List of themes sorted by reliability\n",
        "            primary_themes: Already selected primary themes\n",
        "\n",
        "        Returns:\n",
        "            List of secondary theme dictionaries\n",
        "        \"\"\"\n",
        "        primary_prompts = {theme['prompt'] for theme in primary_themes}\n",
        "        secondary = []\n",
        "\n",
        "        for prompt, stats in ranked_themes:\n",
        "            # Skip if already primary\n",
        "            if prompt in primary_prompts:\n",
        "                continue\n",
        "\n",
        "            # Check if qualifies as secondary\n",
        "            if (stats['consistency'] >= Config.LOW_CONSISTENCY_THRESHOLD or\n",
        "                stats['mean_score'] >= Config.MEDIUM_SCORE_THRESHOLD):\n",
        "\n",
        "                secondary.append({\n",
        "                    'prompt': prompt,\n",
        "                    'consistency': stats['consistency'],\n",
        "                    'mean_score': stats['mean_score'],\n",
        "                    'std_score': stats['std_score'],\n",
        "                    'appears_in_images': stats['appears_in_images'],\n",
        "                    'total_images': stats['total_images'],\n",
        "                    'confidence_level': self._classify_theme_confidence(stats)\n",
        "                })\n",
        "\n",
        "                # Limit to max secondary themes\n",
        "                if len(secondary) >= Config.MAX_SECONDARY_THEMES:\n",
        "                    break\n",
        "\n",
        "        return secondary\n",
        "\n",
        "    def _classify_theme_confidence(self, stats: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Classify confidence level for a single theme.\n",
        "\n",
        "        Args:\n",
        "            stats: Theme statistics dictionary\n",
        "\n",
        "        Returns:\n",
        "            Confidence level: 'high', 'medium', or 'low'\n",
        "        \"\"\"\n",
        "        if (stats['consistency'] >= Config.HIGH_CONSISTENCY_THRESHOLD and\n",
        "            stats['mean_score'] >= Config.HIGH_SCORE_THRESHOLD and\n",
        "            stats['std_score'] < 0.1):\n",
        "            return 'high'\n",
        "        elif (stats['consistency'] >= Config.MEDIUM_CONSISTENCY_THRESHOLD and\n",
        "              stats['mean_score'] >= Config.MEDIUM_SCORE_THRESHOLD):\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'low'\n",
        "\n",
        "    def _compute_consistency_level(self, primary_themes: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Compute overall consistency level across primary themes.\n",
        "\n",
        "        Args:\n",
        "            primary_themes: List of primary theme dictionaries\n",
        "\n",
        "        Returns:\n",
        "            Overall consistency: 'high', 'medium', or 'low'\n",
        "        \"\"\"\n",
        "        if not primary_themes:\n",
        "            return 'low'\n",
        "\n",
        "        # Average consistency of primary themes\n",
        "        avg_consistency = np.mean([theme['consistency'] for theme in primary_themes])\n",
        "\n",
        "        if avg_consistency >= Config.HIGH_CONSISTENCY_THRESHOLD:\n",
        "            return 'high'\n",
        "        elif avg_consistency >= Config.MEDIUM_CONSISTENCY_THRESHOLD:\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'low'\n",
        "\n",
        "    def _compute_overall_confidence(self, primary_themes: List[Dict],\n",
        "                                   consistency_level: str) -> str:\n",
        "        \"\"\"\n",
        "        Compute overall confidence in theme extraction.\n",
        "\n",
        "        Args:\n",
        "            primary_themes: List of primary themes\n",
        "            consistency_level: Overall consistency level\n",
        "\n",
        "        Returns:\n",
        "            Overall confidence: 'high', 'medium', or 'low'\n",
        "        \"\"\"\n",
        "        if not primary_themes:\n",
        "            return 'low'\n",
        "\n",
        "        # Count high-confidence primary themes\n",
        "        high_conf_count = sum(1 for theme in primary_themes\n",
        "                             if theme['confidence_level'] == 'high')\n",
        "\n",
        "        if high_conf_count >= 1 and consistency_level == 'high':\n",
        "            return 'high'\n",
        "        elif high_conf_count >= 1 or consistency_level == 'medium':\n",
        "            return 'medium'\n",
        "        else:\n",
        "            return 'low'\n",
        "\n",
        "    def _generate_summary(self, primary_themes: List[Dict],\n",
        "                         secondary_themes: List[Dict],\n",
        "                         consistency_level: str,\n",
        "                         confidence: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate human-readable summary of theme extraction.\n",
        "\n",
        "        Args:\n",
        "            primary_themes: List of primary themes\n",
        "            secondary_themes: List of secondary themes\n",
        "            consistency_level: Overall consistency\n",
        "            confidence: Overall confidence\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with summary information\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'num_primary_themes': len(primary_themes),\n",
        "            'num_secondary_themes': len(secondary_themes),\n",
        "            'consistency_level': consistency_level,\n",
        "            'confidence': confidence,\n",
        "            'interpretation': self._interpret_results(\n",
        "                primary_themes,\n",
        "                consistency_level,\n",
        "                confidence\n",
        "            )\n",
        "        }\n",
        "\n",
        "    def _interpret_results(self, primary_themes: List[Dict],\n",
        "                          consistency_level: str,\n",
        "                          confidence: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate interpretation text for results.\n",
        "\n",
        "        Args:\n",
        "            primary_themes: List of primary themes\n",
        "            consistency_level: Overall consistency\n",
        "            confidence: Overall confidence\n",
        "\n",
        "        Returns:\n",
        "            Human-readable interpretation string\n",
        "        \"\"\"\n",
        "        if not primary_themes:\n",
        "            return \"No clear themes detected. Images may be too diverse or unclear.\"\n",
        "\n",
        "        if confidence == 'high' and consistency_level == 'high':\n",
        "            return \"Strong, consistent themes detected across all images. High confidence in user preferences.\"\n",
        "        elif confidence == 'high' or consistency_level == 'high':\n",
        "            return \"Clear themes detected with good consistency. Moderate to high confidence in preferences.\"\n",
        "        elif confidence == 'medium' or consistency_level == 'medium':\n",
        "            return \"Moderate theme consistency detected. Some variation across images.\"\n",
        "        else:\n",
        "            return \"Weak or mixed themes detected. Images show diverse preferences or unclear patterns.\"\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"THEME EXTRACTOR COMPLETE: Ready to extract themes\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjvbqyM60ilA",
        "outputId": "00d71d6a-aa9f-48f6-90f5-4661d7a769fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "THEME EXTRACTOR: Initializing theme extraction engine\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "THEME EXTRACTOR COMPLETE: Ready to extract themes\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "================================================================================\n",
        "RUN THEME EXTRACTION\n",
        "================================================================================\n",
        "Purpose: Execute theme extraction pipeline on Step 1 data.\n",
        "================================================================================"
      ],
      "metadata": {
        "id": "NJb3deBL00mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "CELL 6: RUN THEME EXTRACTION\n",
        "================================================================================\n",
        "Purpose: Execute theme extraction pipeline on Step 1 data.\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXECUTING THEME EXTRACTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify data is loaded\n",
        "if not data_loaded or step1_data is None:\n",
        "    print(\"\\nERROR: Step 1 data not loaded\")\n",
        "    print(\"Please run Cell 4 first to load the data.\")\n",
        "    print(\"=\"*80)\n",
        "    theme_results = None\n",
        "else:\n",
        "    try:\n",
        "        # Initialize theme extractor\n",
        "        print(\"\\nInitializing theme extractor...\")\n",
        "        extractor = ThemeExtractor(step1_data)\n",
        "\n",
        "        # Run theme extraction\n",
        "        print(\"\\nStarting theme extraction pipeline...\")\n",
        "        theme_results = extractor.extract_themes()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"THEME EXTRACTION SUCCESSFUL\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Display high-level summary\n",
        "        print(\"\\nExtraction Summary:\")\n",
        "        print(f\"  Images analyzed: {theme_results['num_images_analyzed']}\")\n",
        "        print(f\"  Primary themes found: {theme_results['summary']['num_primary_themes']}\")\n",
        "        print(f\"  Secondary themes found: {theme_results['summary']['num_secondary_themes']}\")\n",
        "        print(f\"  Consistency level: {theme_results['consistency_level'].upper()}\")\n",
        "        print(f\"  Overall confidence: {theme_results['confidence'].upper()}\")\n",
        "\n",
        "        # Display interpretation\n",
        "        print(f\"\\nInterpretation:\")\n",
        "        print(f\"  {theme_results['summary']['interpretation']}\")\n",
        "\n",
        "        # Display outliers if any\n",
        "        if theme_results['outliers_detected']:\n",
        "            print(f\"\\nOutliers detected: {len(theme_results['outliers_detected'])}\")\n",
        "            print(f\"  (These are themes that appear inconsistently)\")\n",
        "        else:\n",
        "            print(f\"\\nNo outliers detected - themes are consistent\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Results stored in variable 'theme_results'\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"\\nERROR: Invalid data\")\n",
        "        print(f\"Details: {str(e)}\")\n",
        "        theme_results = None\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: Theme extraction failed\")\n",
        "        print(f\"Details: {str(e)}\")\n",
        "        import traceback\n",
        "        print(\"\\nFull error trace:\")\n",
        "        print(traceback.format_exc())\n",
        "        theme_results = None\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9jNMrIL08GQ",
        "outputId": "d46fc6f4-2d05-4697-b67a-38332f61089c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXECUTING THEME EXTRACTION\n",
            "================================================================================\n",
            "\n",
            "Initializing theme extractor...\n",
            "\n",
            "Theme extractor initialized:\n",
            "  Total images: 5\n",
            "  Successful analyses: 5\n",
            "\n",
            "Starting theme extraction pipeline...\n",
            "\n",
            "================================================================================\n",
            "THEME EXTRACTION PIPELINE\n",
            "================================================================================\n",
            "\n",
            "Step 1: Collecting scene scores across all images...\n",
            "  Collected scores for 27 unique themes\n",
            "\n",
            "Step 2: Computing theme statistics...\n",
            "  Computed statistics for 27 themes\n",
            "\n",
            "Step 3: Detecting outliers...\n",
            "  No outliers detected\n",
            "\n",
            "Step 4: Ranking themes by consistency and score...\n",
            "  Themes ranked by reliability\n",
            "\n",
            "Step 5: Selecting primary and secondary themes...\n",
            "  Primary themes: 0\n",
            "  Secondary themes: 0\n",
            "\n",
            "Step 6: Computing overall consistency level...\n",
            "  Consistency level: LOW\n",
            "\n",
            "Step 7: Computing overall confidence...\n",
            "  Confidence: LOW\n",
            "\n",
            "Step 8: Generating summary...\n",
            "\n",
            "================================================================================\n",
            "THEME EXTRACTION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "THEME EXTRACTION SUCCESSFUL\n",
            "================================================================================\n",
            "\n",
            "Extraction Summary:\n",
            "  Images analyzed: 5\n",
            "  Primary themes found: 0\n",
            "  Secondary themes found: 0\n",
            "  Consistency level: LOW\n",
            "  Overall confidence: LOW\n",
            "\n",
            "Interpretation:\n",
            "  No clear themes detected. Images may be too diverse or unclear.\n",
            "\n",
            "No outliers detected - themes are consistent\n",
            "\n",
            "================================================================================\n",
            "Results stored in variable 'theme_results'\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Detailed **Results**"
      ],
      "metadata": {
        "id": "xGDHI6F31Vjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "CELL 7: DISPLAY DETAILED THEME EXTRACTION RESULTS\n",
        "================================================================================\n",
        "Purpose: Present comprehensive theme analysis in human-readable format.\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DETAILED THEME EXTRACTION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify results exist\n",
        "if 'theme_results' not in locals() or theme_results is None:\n",
        "    print(\"\\nERROR: No theme results found\")\n",
        "    print(\"Please run Cell 6 first to perform theme extraction.\")\n",
        "    print(\"=\"*80)\n",
        "else:\n",
        "    # Section 1: Primary Themes\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SECTION 1: PRIMARY THEMES\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nThese are the dominant, most consistent themes across your images.\")\n",
        "\n",
        "    if theme_results['primary_themes']:\n",
        "        for i, theme in enumerate(theme_results['primary_themes'], 1):\n",
        "            print(f\"\\n{'-'*80}\")\n",
        "            print(f\"PRIMARY THEME {i}\")\n",
        "            print(f\"{'-'*80}\")\n",
        "            print(f\"\\nTheme: {theme['prompt']}\")\n",
        "            print(f\"\\nStatistics:\")\n",
        "\n",
        "            # Consistency bar\n",
        "            consistency_pct = theme['consistency'] * 100\n",
        "            consistency_bar_length = int(theme['consistency'] * 40)\n",
        "            consistency_bar = \"â\" * consistency_bar_length + \"â\" * (40 - consistency_bar_length)\n",
        "            print(f\"  Consistency: {consistency_bar} {consistency_pct:.1f}%\")\n",
        "            print(f\"               (Appears in {theme['appears_in_images']}/{theme['total_images']} images)\")\n",
        "\n",
        "            # Score bar\n",
        "            score_bar_length = int(theme['mean_score'] * 40)\n",
        "            score_bar = \"â\" * score_bar_length + \"â\" * (40 - score_bar_length)\n",
        "            print(f\"  Mean Score:  {score_bar} {theme['mean_score']:.3f}\")\n",
        "\n",
        "            # Standard deviation\n",
        "            std_indicator = \"Low\" if theme['std_score'] < 0.05 else \"Medium\" if theme['std_score'] < 0.1 else \"High\"\n",
        "            print(f\"  Variability: {theme['std_score']:.3f} ({std_indicator})\")\n",
        "\n",
        "            # Confidence\n",
        "            print(f\"  Confidence:  {theme['confidence_level'].upper()}\")\n",
        "\n",
        "            # Interpretation\n",
        "            print(f\"\\nInterpretation:\")\n",
        "            if theme['consistency'] >= 0.9:\n",
        "                print(f\"  This theme appears in nearly all images, indicating a very\")\n",
        "                print(f\"  strong and consistent user preference.\")\n",
        "            elif theme['consistency'] >= 0.7:\n",
        "                print(f\"  This theme appears in most images, indicating a strong\")\n",
        "                print(f\"  user preference with high consistency.\")\n",
        "            elif theme['consistency'] >= 0.5:\n",
        "                print(f\"  This theme appears in more than half the images, suggesting\")\n",
        "                print(f\"  a moderate but clear user preference.\")\n",
        "            else:\n",
        "                print(f\"  This theme appears in some images, indicating a possible\")\n",
        "                print(f\"  user interest but with less consistency.\")\n",
        "    else:\n",
        "        print(\"\\nNo primary themes identified.\")\n",
        "        print(\"This suggests images are too diverse or unclear.\")\n",
        "\n",
        "    # Section 2: Secondary Themes\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"SECTION 2: SECONDARY THEMES\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nThese provide additional context and supporting characteristics.\")\n",
        "\n",
        "    if theme_results['secondary_themes']:\n",
        "        for i, theme in enumerate(theme_results['secondary_themes'], 1):\n",
        "            print(f\"\\n{'-'*80}\")\n",
        "            print(f\"SECONDARY THEME {i}\")\n",
        "            print(f\"{'-'*80}\")\n",
        "            print(f\"\\nTheme: {theme['prompt']}\")\n",
        "\n",
        "            # Compact statistics\n",
        "            consistency_pct = theme['consistency'] * 100\n",
        "            print(f\"  Consistency: {consistency_pct:.1f}% ({theme['appears_in_images']}/{theme['total_images']} images)\")\n",
        "            print(f\"  Mean Score: {theme['mean_score']:.3f}\")\n",
        "            print(f\"  Confidence: {theme['confidence_level'].upper()}\")\n",
        "    else:\n",
        "        print(\"\\nNo secondary themes identified.\")\n",
        "\n",
        "    # Section 3: Outlier Analysis\n",
        "    if theme_results['outliers_detected']:\n",
        "        print(\"\\n\\n\" + \"=\"*80)\n",
        "        print(\"SECTION 3: OUTLIER ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nOutliers are themes that appear inconsistently across images.\")\n",
        "        print(\"They may indicate:\")\n",
        "        print(\"  - One image is different from others\")\n",
        "        print(\"  - Mixed user preferences\")\n",
        "        print(\"  - Misclassification by the model\")\n",
        "\n",
        "        # Group outliers by type\n",
        "        high_outliers = [o for o in theme_results['outliers_detected'] if o['type'] == 'high']\n",
        "        low_outliers = [o for o in theme_results['outliers_detected'] if o['type'] == 'low']\n",
        "\n",
        "        if high_outliers:\n",
        "            print(f\"\\nHigh Score Outliers ({len(high_outliers)}):\")\n",
        "            print(\"(Theme scored much higher in one image than average)\")\n",
        "            for outlier in high_outliers[:5]:  # Show top 5\n",
        "                print(f\"\\n  Theme: {outlier['prompt'][:60]}...\")\n",
        "                print(f\"  Image index: {outlier['image_index']}\")\n",
        "                print(f\"  Score: {outlier['score']:.3f} (Average: {outlier['mean']:.3f})\")\n",
        "                print(f\"  Deviation: {outlier['deviation']:.2f} standard deviations\")\n",
        "\n",
        "        if low_outliers:\n",
        "            print(f\"\\nLow Score Outliers ({len(low_outliers)}):\")\n",
        "            print(\"(Theme scored much lower in one image than average)\")\n",
        "            for outlier in low_outliers[:5]:  # Show top 5\n",
        "                print(f\"\\n  Theme: {outlier['prompt'][:60]}...\")\n",
        "                print(f\"  Image index: {outlier['image_index']}\")\n",
        "                print(f\"  Score: {outlier['score']:.3f} (Average: {outlier['mean']:.3f})\")\n",
        "                print(f\"  Deviation: {outlier['deviation']:.2f} standard deviations\")\n",
        "\n",
        "    # Section 4: Overall Assessment\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"SECTION 4: OVERALL ASSESSMENT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nImages Analyzed: {theme_results['num_images_analyzed']}\")\n",
        "    print(f\"Primary Themes: {theme_results['summary']['num_primary_themes']}\")\n",
        "    print(f\"Secondary Themes: {theme_results['summary']['num_secondary_themes']}\")\n",
        "\n",
        "    print(f\"\\nConsistency Level: {theme_results['consistency_level'].upper()}\")\n",
        "    consistency_desc = {\n",
        "        'high': \"Themes are very consistent across images. Strong signal.\",\n",
        "        'medium': \"Themes show moderate consistency. Some variation present.\",\n",
        "        'low': \"Themes are inconsistent. Images may be diverse.\"\n",
        "    }\n",
        "    print(f\"  {consistency_desc.get(theme_results['consistency_level'], 'Unknown')}\")\n",
        "\n",
        "    print(f\"\\nOverall Confidence: {theme_results['confidence'].upper()}\")\n",
        "    confidence_desc = {\n",
        "        'high': \"High confidence in identified themes. Reliable for next steps.\",\n",
        "        'medium': \"Moderate confidence. Results are reasonable but verify.\",\n",
        "        'low': \"Low confidence. Results may not be reliable.\"\n",
        "    }\n",
        "    print(f\"  {confidence_desc.get(theme_results['confidence'], 'Unknown')}\")\n",
        "\n",
        "    print(f\"\\nInterpretation:\")\n",
        "    print(f\"  {theme_results['summary']['interpretation']}\")\n",
        "\n",
        "    # Section 5: Recommendations for Step 3\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"SECTION 5: RECOMMENDATIONS FOR STEP 3\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nBased on the extracted themes, here are recommendations for\")\n",
        "    print(\"geo-location identification (Step 3):\")\n",
        "\n",
        "    if theme_results['confidence'] == 'high':\n",
        "        print(\"\\nâ Recommendation: PROCEED WITH CONFIDENCE\")\n",
        "        print(\"  - Primary themes are clear and consistent\")\n",
        "        print(\"  - Use these themes for geo-location matching\")\n",
        "        print(\"  - Both landmark and theme-based matching should work well\")\n",
        "    elif theme_results['confidence'] == 'medium':\n",
        "        print(\"\\nâ  Recommendation: PROCEED WITH CAUTION\")\n",
        "        print(\"  - Themes are moderately consistent\")\n",
        "        print(\"  - Rely more on landmark recognition if available\")\n",
        "        print(\"  - Use themes as supporting evidence\")\n",
        "    else:\n",
        "        print(\"\\nâ  Recommendation: REVIEW IMAGES\")\n",
        "        print(\"  - Themes are weak or inconsistent\")\n",
        "        print(\"  - Consider uploading more focused images\")\n",
        "        print(\"  - Landmark recognition will be more reliable than theme matching\")\n",
        "\n",
        "    # Check for specific regional themes\n",
        "    print(\"\\nRegional Theme Detection:\")\n",
        "    regional_themes_found = []\n",
        "    for theme in theme_results['primary_themes'] + theme_results['secondary_themes']:\n",
        "        prompt_lower = theme['prompt'].lower()\n",
        "        if 'goa' in prompt_lower:\n",
        "            regional_themes_found.append(('Goa', theme['consistency']))\n",
        "        elif 'kerala' in prompt_lower or 'backwater' in prompt_lower:\n",
        "            regional_themes_found.append(('Kerala', theme['consistency']))\n",
        "        elif 'andaman' in prompt_lower:\n",
        "            regional_themes_found.append(('Andaman', theme['consistency']))\n",
        "        elif 'konkan' in prompt_lower:\n",
        "            regional_themes_found.append(('Konkan', theme['consistency']))\n",
        "        elif 'tamil nadu' in prompt_lower:\n",
        "            regional_themes_found.append(('Tamil Nadu', theme['consistency']))\n",
        "\n",
        "    if regional_themes_found:\n",
        "        print(\"  Regional indicators detected:\")\n",
        "        for region, consistency in regional_themes_found:\n",
        "            print(f\"    - {region} ({consistency*100:.0f}% consistency)\")\n",
        "        print(\"  These can help narrow down geo-location in Step 3\")\n",
        "    else:\n",
        "        print(\"  No specific regional indicators detected\")\n",
        "        print(\"  Step 3 will rely on landmark recognition and generic themes\")\n",
        "\n",
        "    # Theme characteristics summary\n",
        "    print(\"\\nTheme Characteristics Summary:\")\n",
        "    all_themes = theme_results['primary_themes'] + theme_results['secondary_themes']\n",
        "\n",
        "    # Extract keywords from themes\n",
        "    keywords = defaultdict(int)\n",
        "    for theme in all_themes:\n",
        "        prompt_lower = theme['prompt'].lower()\n",
        "\n",
        "        # Water/Beach keywords\n",
        "        if any(word in prompt_lower for word in ['beach', 'sand', 'shore', 'coast']):\n",
        "            keywords['beach'] += 1\n",
        "        if any(word in prompt_lower for word in ['water', 'sea', 'ocean']):\n",
        "            keywords['water'] += 1\n",
        "\n",
        "        # Vegetation\n",
        "        if any(word in prompt_lower for word in ['palm', 'tree', 'coconut', 'vegetation']):\n",
        "            keywords['vegetation'] += 1\n",
        "\n",
        "        # Activities\n",
        "        if any(word in prompt_lower for word in ['fishing', 'boat']):\n",
        "            keywords['fishing'] += 1\n",
        "        if any(word in prompt_lower for word in ['sport', 'activity']):\n",
        "            keywords['activities'] += 1\n",
        "\n",
        "        # Characteristics\n",
        "        if any(word in prompt_lower for word in ['pristine', 'clear', 'turquoise']):\n",
        "            keywords['pristine'] += 1\n",
        "        if any(word in prompt_lower for word in ['rocky', 'cliff']):\n",
        "            keywords['rocky'] += 1\n",
        "        if any(word in prompt_lower for word in ['tropical']):\n",
        "            keywords['tropical'] += 1\n",
        "        if any(word in prompt_lower for word in ['secluded', 'offbeat']):\n",
        "            keywords['secluded'] += 1\n",
        "\n",
        "    if keywords:\n",
        "        print(\"  Key characteristics detected:\")\n",
        "        sorted_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)\n",
        "        for keyword, count in sorted_keywords[:5]:\n",
        "            print(f\"    - {keyword.capitalize()}: {count} theme(s)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1XM9d3X1j64",
        "outputId": "2afe306b-5d84-4de0-be11-5a88f02e2642"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DETAILED THEME EXTRACTION RESULTS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "SECTION 1: PRIMARY THEMES\n",
            "================================================================================\n",
            "\n",
            "These are the dominant, most consistent themes across your images.\n",
            "\n",
            "No primary themes identified.\n",
            "This suggests images are too diverse or unclear.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SECTION 2: SECONDARY THEMES\n",
            "================================================================================\n",
            "\n",
            "These provide additional context and supporting characteristics.\n",
            "\n",
            "No secondary themes identified.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SECTION 4: OVERALL ASSESSMENT\n",
            "================================================================================\n",
            "\n",
            "Images Analyzed: 5\n",
            "Primary Themes: 0\n",
            "Secondary Themes: 0\n",
            "\n",
            "Consistency Level: LOW\n",
            "  Themes are inconsistent. Images may be diverse.\n",
            "\n",
            "Overall Confidence: LOW\n",
            "  Low confidence. Results may not be reliable.\n",
            "\n",
            "Interpretation:\n",
            "  No clear themes detected. Images may be too diverse or unclear.\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SECTION 5: RECOMMENDATIONS FOR STEP 3\n",
            "================================================================================\n",
            "\n",
            "Based on the extracted themes, here are recommendations for\n",
            "geo-location identification (Step 3):\n",
            "\n",
            "â  Recommendation: REVIEW IMAGES\n",
            "  - Themes are weak or inconsistent\n",
            "  - Consider uploading more focused images\n",
            "  - Landmark recognition will be more reliable than theme matching\n",
            "\n",
            "Regional Theme Detection:\n",
            "  No specific regional indicators detected\n",
            "  Step 3 will rely on landmark recognition and generic themes\n",
            "\n",
            "Theme Characteristics Summary:\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}