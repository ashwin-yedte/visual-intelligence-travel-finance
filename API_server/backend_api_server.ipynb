{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM998QOdF6Q21nVSNGolphz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwin-yedte/visual-intelligence-travel-finance/blob/main/backend_api_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VLM INTELLIGENCE LAYER\n",
        "\n",
        "\n",
        "UNIFIED BACKEND API\n",
        "\n",
        "\n",
        "Complete pipeline: Steps 1-2-3-4 in single API call\n",
        "\n",
        "Run this AFTER loading all Step 1-4 cells\n",
        "\n",
        "# =================================================================\n",
        "PREREQUISITES\n",
        "# =================================================================\n",
        "\n",
        "BEFORE RUNNING THIS:\n",
        "1. Run ALL cells from Step1_Production_Clean.py\n",
        "2. Run ALL cells from Step2_Destination_Matching.py\n",
        "3. Run ALL cells from Step3_Theme_Aggregation.py\n",
        "4. Run ALL cells from Step4_Recommended_Destinations.py\n",
        "5. Set ngrok auth token\n",
        "6. Start server with start_complete_server()\n"
      ],
      "metadata": {
        "id": "g8_VAjxyUnqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =================================================================\n",
        "Step 1: IMPORTS\n",
        "# =================================================================\n"
      ],
      "metadata": {
        "id": "-2Ephdo3Ut8e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKkJsSmkUatP",
        "outputId": "0d096352-e37c-4bb7-9e05-3190e7b5c7c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "UNIFIED BACKEND API - VLM INTELLIGENCE LAYER\n",
            "================================================================================\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n",
            "Imports complete\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"UNIFIED BACKEND API - VLM INTELLIGENCE LAYER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Install pyngrok if not already installed\n",
        "!pip install pyngrok\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "from typing import List\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from threading import Thread\n",
        "\n",
        "print(\"Imports complete\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =================================================================\n",
        "Step 2: CREATE FASTAPI APP\n",
        "# =================================================================\n"
      ],
      "metadata": {
        "id": "_az2oyHyVZvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI(\n",
        "    title=\"VLM Intelligence API \",\n",
        "    description=\"Visual travel destination recommendation system\",\n",
        "    version=\"1.0\"\n",
        ")\n",
        "\n",
        "# Enable CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FastAPI app created\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRDpvzP6WNIm",
        "outputId": "cc289ec4-d51a-41c1-d81e-82f33e10b28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FastAPI app created\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =================================================================\n",
        "Step 3: COMPLETE PIPELINE ENDPOINT\n",
        "# =================================================================\n"
      ],
      "metadata": {
        "id": "WSpmVgyuV_hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"online\",\n",
        "        \"service\": \"VLM Intelligence API - Complete Pipeline\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"pipeline\": \"Steps 1-2-3-4\",\n",
        "        \"endpoints\": {\n",
        "            \"health\": \"GET /\",\n",
        "            \"complete_pipeline\": \"POST /api/recommend-destinations\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "@app.post(\"/api/recommend-destinations\")\n",
        "async def recommend_destinations_complete(files: List[UploadFile] = File(...)):\n",
        "    \"\"\"\n",
        "    COMPLETE PIPELINE: Steps 1-2-3-4\n",
        "\n",
        "    User uploads images -> Returns recommended destinations\n",
        "\n",
        "    Pipeline:\n",
        "    1. Image Analysis (validation, CLIP embeddings)\n",
        "    2. Destination Matching (per-image top-10)\n",
        "    3. Theme Aggregation (majority vote, re-ranking)\n",
        "    4. Recommendations (enrich with metadata)\n",
        "\n",
        "    Returns:\n",
        "        JSON with user profile and top 10 recommended destinations\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPLETE PIPELINE REQUEST\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Files received: \" + str(len(files)))\n",
        "\n",
        "        # ==================================================================\n",
        "        # STEP 1: IMAGE ANALYSIS\n",
        "        # ==================================================================\n",
        "\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"STEP 1: IMAGE ANALYSIS\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        # Convert files to dict\n",
        "        files_dict = {}\n",
        "        for file in files:\n",
        "            image_bytes = await file.read()\n",
        "            files_dict[file.filename] = image_bytes\n",
        "\n",
        "        # Analyze images\n",
        "        step1_result = analyze_user_images(files_dict)\n",
        "\n",
        "        if step1_result['status'] == 'error':\n",
        "            return JSONResponse(\n",
        "                status_code=400,\n",
        "                content={\n",
        "                    \"status\": \"error\",\n",
        "                    \"step\": \"step1_image_analysis\",\n",
        "                    \"error\": step1_result.get('error'),\n",
        "                    \"error_code\": step1_result.get('error_code'),\n",
        "                    \"validation_errors\": step1_result.get('validation_errors', [])\n",
        "                }\n",
        "            )\n",
        "\n",
        "        save_step1_outputs(step1_result)\n",
        "        print(\"Step 1 complete: \" + str(step1_result['num_processed']) + \" images processed\")\n",
        "\n",
        "        # ==================================================================\n",
        "        # STEP 2: DESTINATION MATCHING\n",
        "        # ==================================================================\n",
        "\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"STEP 2: DESTINATION MATCHING\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        import numpy as np\n",
        "        user_embeddings = np.array(step1_result['embeddings'])\n",
        "\n",
        "        step2_result = match_destinations_per_image(user_embeddings)\n",
        "        save_step2_outputs(step2_result)\n",
        "        print(\"Step 2 complete: \" + str(step2_result['total_unique_destinations']) + \" destinations matched\")\n",
        "\n",
        "        # ==================================================================\n",
        "        # STEP 3: THEME AGGREGATION\n",
        "        # ==================================================================\n",
        "\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"STEP 3: THEME AGGREGATION\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        per_image_matches = step2_result['per_image_matches']\n",
        "\n",
        "        theme_analysis = analyze_theme_distribution(per_image_matches)\n",
        "        destination_data = aggregate_destination_data(per_image_matches)\n",
        "        ranked_destinations = rerank_destinations(destination_data, theme_analysis)\n",
        "\n",
        "        save_step3_outputs(theme_analysis, ranked_destinations)\n",
        "        print(\"Step 3 complete: Dominant theme is \" + theme_analysis['dominant_theme'])\n",
        "\n",
        "        # ==================================================================\n",
        "        # STEP 4: RECOMMENDED DESTINATIONS\n",
        "        # ==================================================================\n",
        "\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"STEP 4: RECOMMENDED DESTINATIONS\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        recommendations_data = build_recommendations(ranked_destinations, theme_analysis)\n",
        "        save_step4_outputs(recommendations_data)\n",
        "        print(\"Step 4 complete: \" + str(recommendations_data['total_recommendations']) + \" recommendations ready\")\n",
        "\n",
        "        # ==================================================================\n",
        "        # PREPARE RESPONSE\n",
        "        # ==================================================================\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PIPELINE COMPLETE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        response = {\n",
        "            \"status\": \"success\",\n",
        "            \"pipeline_summary\": {\n",
        "                \"images_uploaded\": step1_result['num_uploaded'],\n",
        "                \"images_processed\": step1_result['num_processed'],\n",
        "                \"destinations_matched\": step2_result['total_unique_destinations'],\n",
        "                \"dominant_theme\": theme_analysis['dominant_theme'],\n",
        "                \"theme_confidence\": round(theme_analysis['theme_confidence'] * 100, 2)\n",
        "            },\n",
        "            \"user_profile\": recommendations_data['user_profile'],\n",
        "            \"recommendations\": recommendations_data['recommendations']\n",
        "        }\n",
        "\n",
        "        return JSONResponse(content=response)\n",
        "\n",
        "    except NameError as e:\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\n",
        "                \"status\": \"error\",\n",
        "                \"error\": \"Pipeline functions not loaded. Did you run all Step 1-4 cells?\",\n",
        "                \"error_code\": \"PIPELINE_NOT_LOADED\",\n",
        "                \"details\": str(e)\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\n",
        "                \"status\": \"error\",\n",
        "                \"error\": \"Server error: \" + str(e),\n",
        "                \"error_code\": \"SERVER_ERROR\",\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "print(\"Complete pipeline endpoint defined\")\n",
        "print(\"=\"*80)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqgfD9PbtQNt",
        "outputId": "80579daa-57d8-46c1-87a0-da3b6990b0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete pipeline endpoint defined\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =================================================================\n",
        "Step 4: VERIFY ALL STEPS LOADED\n",
        "# =================================================================\n"
      ],
      "metadata": {
        "id": "B31_XEDPtgy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_pipeline_loaded():\n",
        "    \"\"\"Check if all Steps 1-4 are loaded and ready.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"VERIFYING COMPLETE PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    required_functions = [\n",
        "        ('analyze_user_images', 'Step 1'),\n",
        "        ('save_step1_outputs', 'Step 1'),\n",
        "        ('match_destinations_per_image', 'Step 2'),\n",
        "        ('save_step2_outputs', 'Step 2'),\n",
        "        ('analyze_theme_distribution', 'Step 3'),\n",
        "        ('aggregate_destination_data', 'Step 3'),\n",
        "        ('rerank_destinations', 'Step 3'),\n",
        "        ('save_step3_outputs', 'Step 3'),\n",
        "        ('build_recommendations', 'Step 4'),\n",
        "        ('save_step4_outputs', 'Step 4')\n",
        "    ]\n",
        "\n",
        "    all_ok = True\n",
        "\n",
        "    for func_name, step in required_functions:\n",
        "        try:\n",
        "            func = globals()[func_name]\n",
        "            print(\"  Found \" + func_name + \" (\" + step + \")\")\n",
        "        except KeyError:\n",
        "            print(\"  MISSING: \" + func_name + \" (\" + step + \")\")\n",
        "            all_ok = False\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if all_ok:\n",
        "        print(\"SUCCESS: Complete pipeline loaded and ready\")\n",
        "    else:\n",
        "        print(\"ERROR: Some pipeline functions missing\")\n",
        "        print(\"Solution: Run all cells from Steps 1-4 first\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    return all_ok\n",
        "\n"
      ],
      "metadata": {
        "id": "C3H5-T1JtkTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==================================================================\n",
        "Step 5: START SERVER\n",
        "# ==================================================================\n"
      ],
      "metadata": {
        "id": "Gnyva4SJtrvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_complete_server():\n",
        "    \"\"\"Start complete pipeline server with ngrok.\"\"\"\n",
        "\n",
        "    if not verify_pipeline_loaded():\n",
        "        print(\"\\nCANNOT START SERVER\")\n",
        "        print(\"Please run all Step 1-4 cells first\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STARTING COMPLETE PIPELINE SERVER\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Start ngrok\n",
        "    print(\"Creating ngrok tunnel...\")\n",
        "    ngrok_tunnel = ngrok.connect(8000)\n",
        "    public_url = ngrok_tunnel.public_url\n",
        "\n",
        "    print(\"\\nSERVER IS RUNNING\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"Public URL: \" + public_url)\n",
        "    print(\"\\nFrontend should use:\")\n",
        "    print(\"  \" + public_url + \"/api/recommend-destinations\")\n",
        "    print(\"\\nEndpoints:\")\n",
        "    print(\"  GET  \" + public_url + \"/\")\n",
        "    print(\"  POST \" + public_url + \"/api/recommend-destinations\")\n",
        "    print(\"\\nPipeline: Steps 1-2-3-4 (complete)\")\n",
        "    print(\"\\nTo stop: Runtime -> Interrupt execution\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Run uvicorn\n",
        "    def run_uvicorn():\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "    thread = Thread(target=run_uvicorn, daemon=True)\n",
        "    thread.start()\n",
        "\n",
        "    try:\n",
        "        thread.join()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nServer stopped\")\n",
        "\n",
        "\n",
        "print(\"\\nComplete backend API ready\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nTO START SERVER:\")\n",
        "print(\"1. Verify pipeline: verify_pipeline_loaded()\")\n",
        "print(\"2. Set ngrok auth: ngrok.set_auth_token('YOUR_TOKEN')\")\n",
        "print(\"3. Start server: start_complete_server()\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC1gpa6btgqF",
        "outputId": "e4114433-1618-469d-9023-3b384129514b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Complete backend API ready\n",
            "================================================================================\n",
            "\n",
            "TO START SERVER:\n",
            "1. Verify pipeline: verify_pipeline_loaded()\n",
            "2. Set ngrok auth: ngrok.set_auth_token('YOUR_TOKEN')\n",
            "3. Start server: start_complete_server()\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_pipeline_loaded()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRa69FvXq_u8",
        "outputId": "684d0a7a-3e1c-45fd-af28-7ff0df032993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "VERIFYING COMPLETE PIPELINE\n",
            "================================================================================\n",
            "  MISSING: analyze_user_images (Step 1)\n",
            "  MISSING: save_step1_outputs (Step 1)\n",
            "  MISSING: match_destinations_per_image (Step 2)\n",
            "  MISSING: save_step2_outputs (Step 2)\n",
            "  MISSING: analyze_theme_distribution (Step 3)\n",
            "  MISSING: aggregate_destination_data (Step 3)\n",
            "  MISSING: rerank_destinations (Step 3)\n",
            "  MISSING: save_step3_outputs (Step 3)\n",
            "  MISSING: build_recommendations (Step 4)\n",
            "  MISSING: save_step4_outputs (Step 4)\n",
            "================================================================================\n",
            "ERROR: Some pipeline functions missing\n",
            "Solution: Run all cells from Steps 1-4 first\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
